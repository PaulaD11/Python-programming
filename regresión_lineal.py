# -*- coding: utf-8 -*-
"""Regresión_lineal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WpZSUfBLgyuB0rvxNxsASYcfreNTRBC8

### **Regresión lineal múltiple**
"""

import sklearn

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import statsmodels.formula.api as smf
import scipy.stats as st

#Leemos el archivo
Data=pd.read_csv("/content/Korn.csv")

#Obtenemos principales medidas estadísticas de la data
Data.describe()

#Definimos la variable dependiente e independientes
model=smf.ols('Weight ~ C(Species)+Length1+Length2+Length3+Height+Width', Data)

#Ajustamos el modelo
Result=model.fit()

#Vemos los resultados del modelo
Result.summary()

#Prueba de significancia conjunta
#Estadístico F menor al 5%
#Se rechaza la hipótesis nula, así que por lo menos un beta es diferente de 0
#Por lo menos una variable es estadísticamente significativa

#Prueba de significancia individual
#P valor menor al 5%
#Se rechaza la hipótesis nula
#La variable es estadísticamente significativa

#MULTICOLINEARIDAD
pd.plotting.scatter_matrix(Data, figsize=(7,7))

sns.pairplot(data=Data, hue="Species", diag_kind="hist", diag_kws={"multiple":"stack"})

#Se hace el test de VIF que detecta multicolinearidad, por encima de 10 la variable genera multicolinearidad
from statsmodels.stats.outliers_influence import variance_inflation_factor
from patsy import dmatrices
y, x=dmatrices('Weight ~ C(Species) + Length1 + Length2 + Length3 + Height + Width', Data, return_type="dataframe")
vif=pd.DataFrame()
vif["VIF"]=[variance_inflation_factor(x.values, i) for i in range (x.shape[1])]
vif["Variables"]=x.columns
vif.round(2)

#Gráficas de errores
fig=plt.figure(figsize=(8, 6))
ax = fig.add_subplot(221)
ax.scatter(np.arange(len(Data)), Result.resid_pearson, color='blue')
ax.set_xlabel('Observations')
ax.set_ylabel('Standard error')

ax=fig.add_subplot(222)
ax.scatter(Result.fittedvalues, Result.resid_pearson, color='green')
ax.set_xlabel('Mean response')
ax.set_ylabel('standard error')

ax=fig.add_subplot(223)
st.probplot(Result.resid_pearson, plot=ax)

ax=fig.add_subplot(224)
ax.hist(Result.resid_pearson, bins=6)
ax.set_xlabel('Standard error')
ax.set_ylabel('Frequency')
ax.set_title('Histogram')

#En el primer gráfico se observa que los errores sean homogeneos a través de las observaciones (eje X)
#No haya un problema de heterocedasticidad
#En la segunda gráfica se evalua la homogeneidad de los errores y que se ajusten al tipo de regresión
#Que estén distribuidos aleatoriamente
#En el tercer gráfico se evidencia qué tanto los errores siguen la recta
#Si se ajustan, los errores siguen una distribución normal
#En el cuarto gráfico también se verifica que los residuos sigann una distribución normal

#Test de White - Prueba de heterocedasticidad
#La varianza no es constante en los errores
from statsmodels.stats.diagnostic import het_white
White_test= het_white(Result.resid, Result.model.exog)
labels=('LM Statistic', 'LM-Test p-value', 'F Statistic', 'F-Test p-value')
print(dict(zip(labels, White_test)))

#Como el p-value está por debajo del 5% se rechaza la hipótesis nula, por lo tanto hay heterocedasticidad en los residuos

#Test de Jarque-Bera - Prueba de normalidad

#La probabilidad del Jarque-Bera está en el summary del modelo (arriba)

#7.00 e-22

#Al estar por debajo del 5% se rechaza la hipótesis nula, por lo que los residuos no se distribuyen normalmente

#Test de Durbin Watson - Prueba de autocorrelación

#Límite inferior 1, 473
#Límite superior 1,783

#Si el estadístico es menor al límite inferior se rechaza la hipótesis nula
#Si el estadístico es mayor al límite superior NO se rehaza la hipótesis nula
#Si el estadístico está entre los límites inferior y superior, la prueba no es concluyente

#El estadístico está en el summary del modelo (arriba)

#0,973

#Como el estadístico es menor al límite inferior, se rechaza la hipótesis nula
#Existe autocorrelación en los residuos

sns.lmplot(x="Height", y="Weight", data=Data, hue="Species")